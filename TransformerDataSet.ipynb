{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJtq6z080llI0R5uAb7lay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josh-ashkinaze/transform/blob/main/TransformerDataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt8pls5xIWtT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def extract_paragraphs(text, min_lines, n_paragraphs, line_split=\"\\n\"):\n",
        "    \"\"\"\n",
        "    Extracts paragraphs from a given text. A paragraph is defined as a contiguous\n",
        "    block of text separated by the specified line split character and having a minimum number of lines.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text from which paragraphs are to be extracted.\n",
        "        min_lines (int): The minimum number of lines required for a block of text to be considered a paragraph.\n",
        "        n_paragraphs (int): The number of paragraphs to extract that meet the minimum line requirement.\n",
        "        line_split (str, optional): The character or string used to split the text into lines. Default is '\\n'.\n",
        "\n",
        "    Returns:\n",
        "        list of str: A list containing the extracted paragraphs. Each paragraph is a string.\n",
        "\n",
        "    The function iterates through the lines of the input text, split by the line_split character.\n",
        "    It accumulates lines into a paragraph until a blank line or the line split character is encountered.\n",
        "    If the accumulated lines meet or exceed the `min_lines` requirement, the paragraph is added to\n",
        "    the result list. This process repeats until either the end of the text is reached or the required\n",
        "    number of paragraphs (`n_paragraphs`) is extracted. If the end of the text is reached and the current\n",
        "    paragraph meets the minimum line requirement but hasn't been added yet, it will be included in the result.\n",
        "    \"\"\"\n",
        "\n",
        "    lines = text.split(line_split)\n",
        "    paragraphs = []\n",
        "    current_paragraph = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Add non-empty lines to the current paragraph\n",
        "            current_paragraph.append(line)\n",
        "        else:\n",
        "            # Check if the current paragraph meets the minimum line requirement\n",
        "            if len(current_paragraph) >= min_lines:\n",
        "                paragraphs.append(line_split.join(current_paragraph))\n",
        "                if len(paragraphs) == n_paragraphs:  # Check if we have required number of paragraphs\n",
        "                    break\n",
        "            current_paragraph = []\n",
        "\n",
        "    # Check the last paragraph if end of text is reached\n",
        "    if current_paragraph and len(current_paragraph) >= min_lines and len(paragraphs) < n_paragraphs:\n",
        "        paragraphs.append(line_split.join(current_paragraph))\n",
        "\n",
        "    return paragraphs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Articles\n",
        "df = pd.read_csv() #need to figure out how to input all the csvs\n",
        "contents = df.iloc[:,-1].to_dict()\n",
        "article_names = df.iloc[:,0].to_dict()\n",
        "list_of_snippets = {}\n",
        "for i in range(100):\n",
        "  article_name = article_names.get(i)\n",
        "  content = contents.get(i)\n",
        "  val = extract_paragraphs_on_content(content)\n",
        "  list_of_snippets.append({str('article_' + i):f'{article_name}','snippet': f'{val}'})\n",
        "json_result = json.dumps(list_of_snippets)"
      ],
      "metadata": {
        "id": "yYV8UOMTIdhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Songs\n",
        "df = pd.read_csv(wasabi_songs.csv)\n",
        "songs = dcterms:title\n",
        "chords = dcterms:chord #am i doing this correctly and where is verse\n",
        "list_of_snippets = {}\n",
        "for i in range(100):\n",
        "  song_name = songs.get(i)\n",
        "  content = chords.get(i)\n",
        "  list_of_snippets.append({str('song_' + i):f'{song_name}','snippet': f'{content}'})\n",
        "json_result = json.dumps(list_of_snippets)"
      ],
      "metadata": {
        "id": "h5Vg5TsbIeld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Book\n",
        "df = pd.read_csv(stories.csv)\n",
        "contents = df.iloc[:,1].to_dict()\n",
        "book_names = df.iloc[:,0].to_dict()\n",
        "list_of_snippets = {}\n",
        "for i in range(100):\n",
        "  book_name = article_names.get(i)\n",
        "  content = contents.get(i)\n",
        "  val = extract_paragraphs_on_content(content)\n",
        "  list_of_snippets.append({str('book_' + i):f'{book_name}','snippet': f'{val}'})\n",
        "json_result = json.dumps(list_of_snippets)"
      ],
      "metadata": {
        "id": "yEyfxfLyIe0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie Scripts\n",
        "df = pd.read_csv(imdb_top_1000.csv)\n",
        "contents = df.iloc[:,8].to_dict()\n",
        "movie_names = df.iloc[:,2].to_dict()\n",
        "list_of_snippets = {}\n",
        "for i in range(100):\n",
        "  movie_name = movie_names.get(i)\n",
        "  content = contents.get(i)\n",
        "  val = extract_paragraphs_on_content(content)\n",
        "  list_of_snippets.append({str('article_' + i):f'{movie_name}','snippet': f'{val}'})\n",
        "json_result = json.dumps(list_of_snippets)"
      ],
      "metadata": {
        "id": "cCuqDTlGIfCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}